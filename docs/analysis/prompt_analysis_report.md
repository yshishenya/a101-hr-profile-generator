# Анализ системы промптов для генерации HR профилей А101

**Дата анализа:** 2025-10-25
**Аналитик:** Claude Opus 4.1
**Цель:** Выявление сильных и слабых сторон текущей системы генерации профилей должностей

---

## 1. ТЕКУЩЕЕ СОСТОЯНИЕ ПРОМПТА

### 1.1 Архитектура системы

Система использует **два уровня промптов**:

#### Основной промпт (production/prompt.txt)
- **Объем:** 126 строк, ~15000 символов
- **Подход:** Детальные инструкции с пошаговой логикой
- **Фокус:** Строгое следование схеме и правилам валидации

#### Fallback промпт (generation_prompt.txt)
- **Объем:** 115 строк, ~5000 символов
- **Подход:** Ролевая модель с контекстом и примерами
- **Фокус:** Эталонные примеры и специфика А101

### 1.2 Конфигурация модели

```json
{
  "model": "gpt-5-mini",
  "temperature": 0.1,
  "max_tokens": 20000,
  "response_format": {"type": "json_schema"}
}
```

**Особенности:**
- Использует structured output с JSON schema (strict mode)
- Очень низкая температура (0.1) для детерминированности
- Большой лимит токенов для объемных профилей

### 1.3 Структура основного промпта

Промпт организован в логические секции:

1. **Общие правила и принципы** (строки 3-11)
   - Контекст компании А101
   - Строгое соответствие схеме
   - Использование всех данных
   - Правила обработки пробелов
   - Самопроверка и безопасный режим отказа

2. **Обработка иерархии** (строки 13-25)
   - Специальный блок для переменной глубины
   - Инструкции по игнорированию пустых уровней
   - Использование hierarchy_level и full_hierarchy_path

3. **Детальные инструкции по полям** (строки 26-68)
   - Конкретные указания для каждого поля схемы
   - Примеры заполнения
   - Ссылки на входные переменные

4. **Входные данные** (строки 70-114)
   - Структурированная подача переменных
   - Четкое разделение по блокам
   - XML-теги для больших блоков данных

### 1.4 JSON Schema

Схема включает **обязательные поля reasoning** для ключевых секций:

- `reasoning_context_analysis` - анализ входных данных
- `professional_skills_reasoning` - 8-шаговый процесс формирования навыков
- `responsibility_areas_reasoning` - логика трансформации KPI
- `careerogram_reasoning` - обоснование карьерных путей
- `performance_metrics_reasoning` - извлечение метрик
- `quality_verification` - финальная самопроверка

---

## 2. СИЛЬНЫЕ СТОРОНЫ

### 2.1 Структурированность и методичность ✅

**Отлично проработано:**
- Четкая пошаговая логика генерации
- Обязательные reasoning-поля для самообъяснения логики
- Финальная верификация качества
- Structured output гарантирует валидность JSON

### 2.2 Детализация professional_skills ✅

**Уникальная сильная сторона:**
- 8-шаговый процесс анализа навыков (строки 148-192 в схеме)
- Разделение знаний и умений
- Проверка специфичности и измеримости
- Определение уровней владения
- Множество конкретных примеров

### 2.3 Обработка иерархии ✅

**Хорошо решена проблема:**
- Адаптивность к переменной глубине структуры
- Четкие инструкции по пустым уровням
- Использование hierarchy_level как основного индикатора

### 2.4 Контекстуальность ✅

**Учет специфики:**
- Множественные блоки входных данных (company_map, org_structure, kpi_data, it_systems)
- Ссылки на конкретные переменные в инструкциях
- Enum-списки для корпоративных значений

### 2.5 Примеры и конкретика ✅

**Богатство примеров:**
- Конкретные примеры для каждого типа поля
- Форматы записи с образцами
- Антипримеры (что НЕ писать)

---

## 3. СЛАБЫЕ МЕСТА И ПРОБЛЕМЫ

### 3.1 Избыточная сложность reasoning-полей ⚠️

**Проблема:**
- 8 обязательных шагов для professional_skills_reasoning создают огромный overhead
- Reasoning-поля занимают 30-40% объема выходного JSON
- Увеличивают стоимость генерации и время ответа

**Влияние на качество:**
- Модель тратит токены на метаанализ вместо контента
- Возможна усталость модели от избыточных reasoning

### 3.2 Противоречивые инструкции ⚠️

**Выявленные противоречия:**

1. **Безопасный режим отказа vs обязательность полей**
   - Строка 11: "верни JSON-объект с error"
   - Но схема требует ВСЕ обязательные поля
   - Невозможно вернуть только {"error": "..."} при strict schema

2. **Использование инференсов vs точность**
   - Правило 4: "сделай логически обоснованное допущение"
   - Но quality_verification требует отслеживать все инференсы
   - Нет четкой границы когда можно/нельзя делать допущения

### 3.3 Перегруженность примерами в схеме ⚠️

**Проблема:**
- Описания полей в схеме содержат 5-10 примеров каждое
- Схема раздута до 600+ строк
- Трудно найти актуальную информацию

**Влияние:**
- Модель может запутаться в избытке примеров
- Сложно поддерживать и обновлять

### 3.4 Несогласованность двух промптов ⚠️

**Различия подходов:**
- Production: фокус на правилах и схеме
- Fallback: фокус на примерах и контексте
- Нет единой системы, что создает непредсказуемость

### 3.5 Отсутствие валидации входных данных ⚠️

**Проблемы:**
- Нет проверки полноты входных переменных
- Нет fallback для отсутствующих данных
- Молчаливое использование пустых значений

### 3.6 Жесткие enum-ограничения ⚠️

**Примеры проблем:**
- department_broad: только 9 фиксированных блоков
- personal_qualities: ограничен списком из 25 качеств
- Нет гибкости для новых подразделений

### 3.7 Неоптимальная температура ⚠️

**temperature: 0.1**
- Слишком низкая даже для structured output
- Может приводить к repetitive и uncreative ответам
- Рекомендуется 0.3-0.5 для баланса

---

## 4. КОНКРЕТНЫЕ РЕКОМЕНДАЦИИ

### 4.1 Оптимизация reasoning-полей

**Текущий промпт:**
```json
"professional_skills_reasoning": {
  "step1_responsibility_analysis": "...",
  "step2_knowledge_vs_skills_separation": "...",
  ...
  "step8_completeness_validation": "..."
}
```

**Улучшенный промпт:**
```json
"professional_skills_reasoning": {
  "type": "string",
  "description": "Кратко опишите логику выбора навыков: какие обязанности требуют каких компетенций, почему выбран такой уровень владения (100-200 слов)"
}
```

**Эффект:** Сокращение объема на 60%, фокус на контенте

### 4.2 Устранение противоречий

**Добавить в начало промпта:**
```
## ПРИОРИТЕТЫ ПРИ КОНФЛИКТЕ ПРАВИЛ:
1. Валидность JSON-схемы - высший приоритет
2. Использование реальных данных > инференсы
3. При критической нехватке данных: заполнить минимальными значениями с пометкой в quality_verification
4. НЕ использовать режим {"error": "..."} - всегда генерировать полный профиль
```

### 4.3 Система few-shot примеров

**Вместо примеров в схеме, создать отдельный блок:**

```
## ЭТАЛОННЫЙ ПРИМЕР ПРОФИЛЯ:
<example_profile>
{
  "position_title": "Ведущий специалист по автоматизации",
  "professional_skills": [
    {
      "skill_category": "Разработка на платформе 1С:Предприятие 8.3",
      "specific_skills": [
        {
          "skill_name": "Знание платформы 1С:Предприятие 8.3 (управляемые формы, СКД, БСП, механизмы обмена)",
          "proficiency_level": 3
        }
      ]
    }
  ]
}
</example_profile>

Используй этот пример как образец качества и детализации.
```

### 4.4 Динамические enum через контекст

**Вместо жестких enum в схеме:**
```json
"department_broad": {
  "type": "string",
  "description": "Выбери из списка блоков в company_map или укажи 'Другое: [название]' для новых"
}
```

### 4.5 Валидация входных данных

**Добавить в начало промпта:**
```
## ПРОВЕРКА ВХОДНЫХ ДАННЫХ:
Перед генерацией убедись, что получены:
- position (обязательно)
- department (обязательно)
- hierarchy_level (обязательно)
- full_hierarchy_path (обязательно)

Если критические данные отсутствуют, пометь это в quality_verification.confidence_level = "low"
```

### 4.6 Оптимизация температуры

**Изменить в config.json:**
```json
{
  "temperature": 0.3,
  "top_p": 0.95
}
```

### 4.7 Система промптов с приоритетами

**Создать иерархию:**
```
prompts/
  ├── core/
  │   └── base_instructions.txt (общие правила)
  ├── context/
  │   └── company_specific.txt (контекст А101)
  ├── examples/
  │   └── profile_samples.json (2-3 эталонных примера)
  └── schema/
      └── simplified_schema.json (без примеров в описаниях)
```

### 4.8 Мониторинг качества

**Добавить в промпт:**
```
## МЕТРИКИ КАЧЕСТВА (заполни в metadata):
- completeness_score: % заполненных полей от возможных
- inference_ratio: % полей с допущениями
- confidence_score: общая уверенность 0-100
```

---

## 5. КРИТИЧЕСКИЕ УЛУЧШЕНИЯ (QUICK WINS)

### 5.1 Немедленные изменения (1 день)

1. **Увеличить temperature до 0.3**
   - Файл: `config.json`
   - Улучшит креативность без потери структуры

2. **Упростить reasoning поля**
   - Сократить с 8 шагов до 1-2 ключевых
   - Уменьшит объем на 40%

3. **Убрать противоречие с error режимом**
   - Удалить строку 11 из промпта
   - Всегда генерировать полный профиль

### 5.2 Краткосрочные улучшения (1 неделя)

1. **Вынести примеры из схемы**
   - Создать отдельный файл с 2-3 эталонными профилями
   - Упростить схему до 200-300 строк

2. **Добавить валидацию входных данных**
   - Проверка наличия критических переменных
   - Явное указание confidence при нехватке данных

3. **Создать A/B тестирование**
   - Сравнить production и fallback промпты
   - Выбрать лучший как основной

### 5.3 Долгосрочные улучшения (1 месяц)

1. **Модульная система промптов**
   - Разделить на core + context + examples
   - Легче поддерживать и обновлять

2. **Динамическая схема**
   - Генерировать enum из актуальных данных
   - Адаптация под новые подразделения

3. **Система обратной связи**
   - Собирать оценки качества от HR
   - Автоматически улучшать промпты

---

## 6. ЗАКЛЮЧЕНИЕ

### Общая оценка: 7/10

**Сильные стороны:**
- Отличная структурированность
- Богатая детализация навыков
- Хорошая адаптация к иерархии

**Критические проблемы:**
- Избыточность reasoning-полей
- Противоречивые инструкции
- Слишком низкая температура

### Ожидаемый эффект от улучшений:

- **Скорость генерации:** +40% (меньше reasoning)
- **Качество контента:** +25% (фокус на содержании)
- **Стоимость:** -30% (меньше токенов)
- **Поддерживаемость:** +50% (модульность)

### Приоритет действий:

1. **СЕГОДНЯ:** Изменить temperature, упростить reasoning
2. **НЕДЕЛЯ:** Вынести примеры, добавить валидацию
3. **МЕСЯЦ:** Модульная архитектура, обратная связь

---

*Отчет подготовлен на основе анализа production промптов системы генерации HR-профилей А101*
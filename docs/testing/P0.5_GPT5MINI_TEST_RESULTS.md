# P0.5 Test Results: gpt-5-mini Reliability Assessment

**Date**: 2025-10-26
**Model Tested**: gpt-5-mini (via OpenRouter)
**Langfuse Version**: v52 (fixed response_format schema)
**Status**: ⛔ **FAILED** - Model NOT reliable for production

---

## Executive Summary

After fixing the `response_format` schema validation issues (added `additionalProperties: false` to 10 nested objects), tested `gpt-5-mini` model with Langfuse v52 containing P0.5 prompt enhancements.

**Critical Finding**: **100% JSON generation failure rate** (2/2 attempts failed with JSON decode errors).

**Recommendation**: **DO NOT USE gpt-5-mini** for HR profile generation with P0.5 prompts. Model is unreliable for structured outputs with large/complex prompts.

---

## Test Configuration

### Langfuse v52 Configuration
```json
{
  "model": "gpt-5-mini",
  "temperature": 0.1,
  "max_tokens": 20000,
  "response_format": {
    "type": "json_schema",
    "json_schema": {
      "name": "UniversalCorporateJobProfile",
      "strict": true,
      "schema": {
        // Fixed schema with additionalProperties: false in 10 nested objects
      }
    }
  }
}
```

### Schema Fixes Applied (v51 → v52)
```
✅ Added additionalProperties at: properties.responsibility_areas.items
✅ Added additionalProperties at: properties.careerogram
✅ Added additionalProperties at: properties.careerogram.properties.source_positions
✅ Added additionalProperties at: properties.careerogram.properties.target_pathways
✅ Added additionalProperties at: properties.careerogram.properties.target_pathways.properties.vertical_growth.items
✅ Added additionalProperties at: properties.careerogram.properties.target_pathways.properties.vertical_growth.items.properties.competency_bridge
✅ Added additionalProperties at: properties.careerogram.properties.target_pathways.properties.horizontal_growth.items
✅ Added additionalProperties at: properties.careerogram.properties.target_pathways.properties.horizontal_growth.items.properties.competency_bridge
✅ Added additionalProperties at: properties.careerogram.properties.target_pathways.properties.expert_growth.items
✅ Added additionalProperties at: properties.careerogram.properties.target_pathways.properties.expert_growth.items.properties.competency_bridge
```

**Result**: 0 schema validation errors. All objects compliant with OpenAI Structured Outputs requirements.

### P0.5 Prompt Enhancements
- **P0.5.1**: Strengthened P0.2 enforcement (mandatory soft skills methodologies)
- **P0.5.2**: Strengthened P0.4 enforcement (proficiency level uniqueness)
- **Prompt size**: 921 lines, 58 KB (up from 823 lines, 51 KB in P0)

---

## Test Results

### Attempt 1: Backend Python Developer Test V52

**Request**:
```json
{
  "department": "Департамент информационных технологий",
  "position": "Backend Python Developer Test V52"
}
```

**Task ID**: `dbe0f74c-b475-45d3-8446-a44f21b15ad9`

**Result**: ❌ **FAILED**
```
JSONDecodeError: Expecting value: line 343 column 1 (char 1881)
Langfuse generation failed after 72.43s
❌ Profile generation completed in 72.43s
```

**Analysis**:
- Generation ran for 72.43 seconds
- Model generated response but JSON is malformed
- Error at line 343, character position 1881
- Likely incomplete JSON or syntax error mid-generation

---

### Attempt 2: HR Business Partner V52 Retry

**Request**:
```json
{
  "department": "Департамент персонала",
  "position": "HR Business Partner V52 Retry"
}
```

**Task ID**: `d727ddcb-2918-4d93-8c6d-81781dc549d4`

**Result**: ❌ **FAILED**
```
JSONDecodeError: Expecting value: line 687 column 1 (char 3773)
Langfuse generation failed after 144.63s
❌ Profile generation completed in 144.63s
```

**Analysis**:
- Generation ran for 144.63 seconds (2x longer than attempt 1)
- Error at line 687, character position 3773 (2x deeper than attempt 1)
- Different error position suggests non-deterministic failure
- Model struggles with large JSON generation despite strict mode

---

## Failure Pattern Analysis

### JSON Decode Error Positions

| Attempt | Position | Characters | Generation Time |
|---------|----------|------------|-----------------|
| 1 | Line 343 | char 1881 | 72.43s |
| 2 | Line 687 | char 3773 | 144.63s |

**Observations**:
1. **Different failure positions**: Not a fixed bug in prompt/schema
2. **Increasing failure depth**: Attempt 2 got 2x further before failing
3. **Non-deterministic**: Suggests model context/attention issues with long outputs
4. **End-of-JSON truncation**: Both errors at "column 1" suggest premature termination

### Hypothesis: Why gpt-5-mini Fails

**Root Cause**: Model has **limited capacity for long structured outputs**.

**Evidence**:
1. ✅ Schema is valid (tested, 0 validation errors)
2. ✅ `strict: true` enabled
3. ✅ Small prompts work fine (tested earlier)
4. ❌ Large P0.5 prompt (58 KB, 47K input tokens) causes failures

**Theory**:
- `gpt-5-mini` is optimized for speed/cost, not reliability
- Long structured outputs require sustained attention across many tokens
- Model may truncate output when hitting internal limits
- `strict: true` doesn't prevent truncation, only enforces syntax for completed JSON

---

## Comparison: v50 vs v52

### Langfuse v50 (No response_format)
**Config**: response_format removed (due to schema errors)

**Results** (3 attempts):
| Profile | Result | Quality | Issue |
|---------|--------|---------|-------|
| HR Business Partner Test | ✅ SUCCESS | 5.5/10 | Low quality, no enforcement |
| Backend Python Developer | ✅ SUCCESS | 5.5/10 | Low quality, no enforcement |
| Главный бухгалтер | ❌ FAILED | - | JSONDecodeError |
| Менеджер по продажам B2B | ❌ FAILED | - | JSONDecodeError |

**Success Rate**: 50% (2/4)
**Quality**: 5.5/10 (regression from P0 baseline 8.14/10)

### Langfuse v52 (Fixed response_format)
**Config**: response_format with all schema issues fixed

**Results** (2 attempts):
| Profile | Result | Quality | Issue |
|---------|--------|---------|-------|
| Backend Python Developer Test V52 | ❌ FAILED | - | JSONDecodeError line 343 |
| HR Business Partner V52 Retry | ❌ FAILED | - | JSONDecodeError line 687 |

**Success Rate**: 0% (0/2)
**Quality**: N/A (no successful profiles)

---

## Cost Analysis

### Generation Costs (Failed Attempts)

**Attempt 1**: 72.43s
**Attempt 2**: 144.63s
**Total wasted time**: 217 seconds (~3.6 minutes)

**Token consumption**:
- Input tokens: ~47,820 per request
- Output tokens: Partial (truncated)
- Estimated cost per failed attempt: $0.003-0.005

**100% failure rate** means **100% wasted API costs** for v52.

---

## Recommendations

### Priority 1: Change Model ⚠️ URGENT

**Option A: Switch to gpt-4o** (Recommended)
- **Pros**:
  - Much more reliable for structured outputs
  - Handles large/complex schemas better
  - Better instruction following for P0.5 enforcement
- **Cons**:
  - Higher cost (~10-15x gpt-5-mini)
  - Slower generation (~2-3x longer)
- **Success Rate**: Expected 95%+

**Option B: Switch to gemini-2.5-flash** (Alternative)
- **Pros**:
  - Original baseline model (known to work)
  - Fast and cost-effective
  - Good quality (P0 baseline: 8.14/10)
- **Cons**:
  - No structured outputs (relies on prompt instructions)
  - May not enforce P0.5 checkpoints as strictly
- **Success Rate**: Expected 90%+ (based on P0 results)

**Option C: Keep gpt-5-mini, remove response_format**
- **Pros**:
  - 50% success rate (better than 0%)
  - Fast and cheap
- **Cons**:
  - Still 50% failure rate
  - Low quality (5.5/10)
  - No P0.5 enforcement
- **Success Rate**: 50% (tested)

### Priority 2: Simplify P0.5 Prompt

If staying with gpt-5-mini:
1. **Reduce prompt size**: 58 KB → 30-40 KB
   - Remove verbose examples
   - Consolidate redundant instructions
   - Simplify reasoning sections

2. **Simplify response_format schema**:
   - Remove deeply nested structures (careerogram)
   - Flatten professional_skills structure
   - Reduce required fields

3. **Split generation into phases**:
   - Phase 1: Generate basic profile (without P0.5 enhancements)
   - Phase 2: Post-process to add methodologies/frameworks
   - Reduces per-request complexity

### Priority 3: Implement Fallback Strategy

**Hybrid Approach**:
1. Try with gpt-5-mini + response_format
2. If fails → retry WITHOUT response_format
3. If still fails → fallback to gemini-2.5-flash
4. Post-process results to fix missing elements

**Implementation**:
```python
async def generate_profile_with_fallback(dept, position):
    # Try 1: gpt-5-mini with strict schema
    result = await try_generation(model="gpt-5-mini", response_format=schema)
    if result.success:
        return result

    # Try 2: gpt-5-mini without schema
    result = await try_generation(model="gpt-5-mini", response_format=None)
    if result.success:
        return post_process_profile(result)  # Fix missing elements

    # Try 3: Fallback to gemini
    result = await try_generation(model="gemini-2.5-flash", response_format=None)
    return post_process_profile(result)
```

---

## Conclusion

**gpt-5-mini is NOT RELIABLE** for HR profile generation with P0.5 prompts:
- ❌ 100% failure rate with response_format (v52)
- ❌ 50% failure rate without response_format (v50)
- ❌ Low quality even when succeeds (5.5/10 vs baseline 8.14/10)

**BLOCK DEPLOYMENT of gpt-5-mini** until either:
1. Model is changed to gpt-4o or gemini-2.5-flash
2. P0.5 prompt is significantly simplified
3. Fallback strategy is implemented

**Next Actions**:
1. ⏳ URGENT: Discuss with user - which model to use?
2. ⏳ HIGH: If switching models, update Langfuse config
3. ⏳ HIGH: Re-test with new model (4 profiles)
4. ⏳ MEDIUM: If keeping gpt-5-mini, implement fallback strategy

---

**Report Date**: 2025-10-26
**Generated By**: AI Agent (Claude Code)
**Status**: ⛔ BLOCKING - Model change required

"""
DataLoader —Å –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ñ–∏–ª–µ–π –ê101.

–û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –º–∞–ø–ø–∏–Ω–≥–∞
–¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ Langfuse –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–∞.
"""

import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List
from enum import Enum
import logging

from .data_mapper import OrganizationMapper, KPIMapper
from .organization_cache import organization_cache

logger = logging.getLogger(__name__)


class PositionType(Enum):
    """Position type for IT systems relevance categorization."""

    IT_TECHNICAL = "it_technical"  # Full 15K tokens - technical roles
    IT_MANAGEMENT = "it_management"  # 3K tokens - IT leadership
    BUSINESS_TECHNICAL = "business_technical"  # 5K tokens - product/project roles
    BUSINESS_GENERAL = "business_general"  # 1K tokens - general business roles
    SUPPORT = "support"  # 1K tokens - administrative/support roles


# Position keywords mapping for categorization
POSITION_KEYWORDS = {
    PositionType.IT_TECHNICAL: [
        r"–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç",
        r"—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫",
        r"developer",
        r"–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä",
        r"engineer",
        r"–∏–Ω–∂–µ–Ω–µ—Ä",
        r"devops",
        r"–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä",
        r"—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫",
        r"qa",
        r"–∞–Ω–∞–ª–∏—Ç–∏–∫.*–¥–∞–Ω–Ω—ã—Ö",
        r"data",
        r"backend",
        r"frontend",
        r"fullstack",
        r"—Å–∏—Å—Ç–µ–º–Ω.*–∏–Ω–∂–µ–Ω–µ—Ä",
        r"—Å–µ—Ç–µ–≤.*–∏–Ω–∂–µ–Ω–µ—Ä",
    ],
    PositionType.IT_MANAGEMENT: [
        r"—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å.*–∏—Ç",
        r"–¥–∏—Ä–µ–∫—Ç–æ—Ä.*—Ç–µ—Ö–Ω–æ–ª–æ–≥",
        r"–¥–∏—Ä–µ–∫—Ç–æ—Ä.*–∏—Ç",
        r"cto",
        r"cio",
        r"–Ω–∞—á–∞–ª—å–Ω–∏–∫.*—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏",
        r"—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å.*–∏–Ω—Ñ–æ—Ä–º–∞—Ü",
        r"—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å.*—Ü–∏—Ñ—Ä–æ–≤",
        r"–Ω–∞—á–∞–ª—å–Ω–∏–∫.*–∏–Ω—Ñ–æ—Ä–º–∞—Ü",
    ],
    PositionType.BUSINESS_TECHNICAL: [
        r"–ø—Ä–æ–¥—É–∫—Ç",
        r"product",
        r"owner",
        r"–º–µ–Ω–µ–¥–∂–µ—Ä.*–ø—Ä–æ–µ–∫—Ç",
        r"project.*manager",
        r"scrum.*master",
        r"agile",
        r"–±–∏–∑–Ω–µ—Å.*–∞–Ω–∞–ª–∏—Ç–∏–∫",
    ],
    PositionType.BUSINESS_GENERAL: [
        r"–º–µ–Ω–µ–¥–∂–µ—Ä",
        r"—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç",
        r"–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä",
        r"–¥–∏—Ä–µ–∫—Ç–æ—Ä",
        r"—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å",
        r"–Ω–∞—á–∞–ª—å–Ω–∏–∫",
    ],
    PositionType.SUPPORT: [
        r"–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç",
        r"—Å–µ–∫—Ä–µ—Ç–∞—Ä—å",
        r"–ø–æ–º–æ—â–Ω–∏–∫",
        r"—Å—Ç–∞–∂–µ—Ä",
        r"junior",
        r"–¥–µ–ª–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª",
    ],
}


def detect_position_type(position: str, department: str) -> PositionType:
    """
    Detect position type for IT systems relevance.

    Logic:
    1. Check position keywords (most specific)
    2. Check if department is IT-related
    3. Default to BUSINESS_GENERAL

    Args:
        position: Position name
        department: Department name

    Returns:
        PositionType enum value
    """
    pos_lower = position.lower()
    dept_lower = department.lower()

    # Check position keywords by priority (most specific first)
    for pos_type in [
        PositionType.IT_TECHNICAL,
        PositionType.IT_MANAGEMENT,
        PositionType.BUSINESS_TECHNICAL,
        PositionType.SUPPORT,
        PositionType.BUSINESS_GENERAL,
    ]:
        keywords = POSITION_KEYWORDS[pos_type]
        if any(re.search(keyword, pos_lower) for keyword in keywords):
            logger.debug(f"Position '{position}' classified as {pos_type.value} by keyword match")
            return pos_type

    # Department-based fallback for IT departments
    it_dept_keywords = [r"–∏—Ç", r"–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω", r"—Ü–∏—Ñ—Ä–æ–≤", r"–¥–∞–Ω–Ω—ã—Ö", r"digital"]
    if any(re.search(kw, dept_lower) for kw in it_dept_keywords):
        logger.debug(f"Position '{position}' in IT dept '{department}' classified as IT_MANAGEMENT")
        return PositionType.IT_MANAGEMENT

    logger.debug(f"Position '{position}' defaulted to BUSINESS_GENERAL")
    return PositionType.BUSINESS_GENERAL


class DataLoader:
    """
    –ì–ª–∞–≤–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö —Å –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –º–∞–ø–ø–∏–Ω–≥–∞.
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è Langfuse –ø—Ä–æ–º–ø—Ç–æ–≤.
    """

    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∞–ø–ø–∏–Ω–≥–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.org_mapper = OrganizationMapper("data/structure.json")
        self.kpi_mapper = KPIMapper("data/KPI")

        # –ö–µ—à –¥–ª—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        self._cache = {}

        # –ü—É—Ç–∏ –∫ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–º —Ñ–∞–π–ª–∞–º - –≤—Å–µ –≤ ./data
        self.paths = {
            "company_map": Path("data") / "–ö–∞—Ä—Ç–∞ –ö–æ–º–ø–∞–Ω–∏–∏ –ê101.md",
            "org_structure": Path("data") / "structure.json",
            "it_systems": Path("data") / "anonymized_digitization_map.md",
            "json_schema": Path("templates") / "job_profile_schema.json",
        }

    def prepare_langfuse_variables(
        self, department: str, position: str, employee_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –º–∞–ø–ø–∏–Ω–≥–∞ –¥–ª—è Langfuse.

        Args:
            department: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
            position: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏
            employee_name: –§–ò–û —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –°–ª–æ–≤–∞—Ä—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è Langfuse –ø—Ä–æ–º–ø—Ç–∞
        """
        logger.info(f"Preparing variables for {department} - {position}")

        try:
            # üî• FIX: –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ –¥–ª—è –º–µ—Ç–æ–¥–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –µ–≥–æ –æ–∂–∏–¥–∞—é—Ç
            if "/" in department:
                department_parts = [p.strip() for p in department.split("/") if p.strip()]
                department_short_name = department_parts[-1]  # –ü–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç
                logger.info(
                    f"Extracted short department name '{department_short_name}' from path '{department}'"
                )
            else:
                department_short_name = department

            # üéØ –î–ï–¢–ï–†–ú–ò–ù–ò–†–û–í–ê–ù–ù–û–ï –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è)
            org_structure = self._load_org_structure_for_department(department_short_name)

            # üéØ –ù–û–í–û–ï: –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ü–û–õ–ù–û–ô –ò–ï–†–ê–†–•–ò–ò –î–û –ü–û–ó–ò–¶–ò–ò (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è)
            hierarchy_info = self._extract_full_position_path(department, position)
            department_path = hierarchy_info.get("department_path_legacy", department)

            # üéØ –î–ï–¢–ï–†–ú–ò–ù–ò–†–û–í–ê–ù–ù–´–ô –í–´–ë–û–† KPI –§–ê–ô–õ–ê (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è)
            kpi_content = self.kpi_mapper.load_kpi_content(department_short_name)

            # üÜï METADATA: Track KPI source (specific file vs template)
            kpi_metadata = self._detect_kpi_source(department_short_name)

            # üéØ –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –î–ê–ù–ù–´–• –û –ß–ò–°–õ–ï–ù–ù–û–°–¢–ò (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è)
            headcount_info = self.org_mapper.get_headcount_info(department_short_name)
            subordinates_count = self.org_mapper.calculate_subordinates_count(
                department_short_name, position
            )

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å–µ—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            variables = {
                # –û–°–ù–û–í–ù–û–ô –ö–û–ù–¢–ï–ö–°–¢ (–∫–µ—à–∏—Ä—É–µ—Ç—Å—è)
                "company_map": self._load_company_map_cached(),  # ~110K —Å–∏–º–≤–æ–ª–æ–≤
                "json_schema": self._load_profile_schema_cached(),  # ~1K —Ç–æ–∫–µ–Ω–æ–≤ (–Ω—É–∂–Ω–∞ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞)
                # –†–ï–õ–ï–í–ê–ù–¢–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω–∞—è)
                "org_structure": json.dumps(
                    org_structure, ensure_ascii=False, indent=2
                ),  # ~5K —Ç–æ–∫–µ–Ω–æ–≤
                "department_path": department_path,
                # –ü–û–õ–ù–ê–Ø –û–†–ì–ê–ù–ò–ó–ê–¶–ò–û–ù–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º —Ü–µ–ª–∏
                "OrgStructure": json.dumps(
                    self._get_organization_structure_with_target(f"{department}/{position}"),
                    ensure_ascii=False,
                    indent=2,
                ),  # ~229K —Å–∏–º–≤–æ–ª–æ–≤ - –ø–æ–ª–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º
                # –ü–û–ó–ò–¶–ò–û–ù–ù–´–ï –î–ê–ù–ù–´–ï
                "position": position,
                "department": department,  # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å (–∫–∞–∫ –ø–µ—Ä–µ–¥–∞–Ω–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–º)
                "department_name": department_short_name,  # –ö–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è –¥–ª—è –ª–æ–≥–∏–∫–∏ –≤ –ø—Ä–æ–º–ø—Ç–µ
                "employee_name": employee_name or "",
                # –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–ô –ö–û–ù–¢–ï–ö–°–¢ (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–π)
                "kpi_data": kpi_content,  # 0-15K —Ç–æ–∫–µ–Ω–æ–≤
                "kpi_source": kpi_metadata["source"],  # NEW: "specific" or "template"
                "kpi_type": kpi_metadata["dept_type"],  # NEW: "IT", "SALES", "GENERIC" etc
                "it_systems": self._load_it_systems_conditional(
                    position, department_short_name
                ),  # 1K-15K —Ç–æ–∫–µ–Ω–æ–≤ (conditional)
                "it_systems_detail_level": detect_position_type(
                    position, department_short_name
                ).value,  # metadata
                # –î–ê–ù–ù–´–ï –û –ß–ò–°–õ–ï–ù–ù–û–°–¢–ò –ò –ü–û–î–ß–ò–ù–ï–ù–ù–´–•
                "headcount_info": headcount_info,  # –ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
                "subordinates_calculation": subordinates_count,  # –†–∞—Å—á–µ—Ç –ø–æ–¥—á–∏–Ω–µ–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                "department_headcount": headcount_info.get(
                    "headcount"
                ),  # –ü—Ä—è–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
                "headcount_source": headcount_info.get(
                    "headcount_source"
                ),  # –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö –æ —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏
                # –ü–õ–û–°–ö–ò–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï –î–õ–Ø –ü–û–î–ß–ò–ù–ï–ù–ù–û–°–¢–ò (–±–µ–∑ —Ç–æ—á–µ–∫ –¥–ª—è Langfuse)
                "subordinates_departments": subordinates_count.get("departments", 0),
                "subordinates_direct_reports": subordinates_count.get("direct_reports", 0),
                # –ù–û–í–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï –ò–ï–†–ê–†–•–ò–ò (–ë–ª–æ–∫-–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç-–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ-–û—Ç–¥–µ–ª-–ü–æ–¥–û—Ç–¥–µ–ª-–ì—Ä—É–ø–ø–∞)
                "business_block": hierarchy_info.get("business_block", ""),  # –£—Ä–æ–≤–µ–Ω—å 1: –ë–ª–æ–∫
                "department_unit": hierarchy_info.get(
                    "department_unit", ""
                ),  # –£—Ä–æ–≤–µ–Ω—å 2: –î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç
                "section_unit": hierarchy_info.get(
                    "section_unit", ""
                ),  # –£—Ä–æ–≤–µ–Ω—å 3: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ/–û—Ç–¥–µ–ª
                "group_unit": hierarchy_info.get("group_unit", ""),  # –£—Ä–æ–≤–µ–Ω—å 4: –û—Ç–¥–µ–ª
                "sub_section_unit": hierarchy_info.get(
                    "sub_section_unit", ""
                ),  # –£—Ä–æ–≤–µ–Ω—å 5: –ü–æ–¥-–æ—Ç–¥–µ–ª
                "final_group_unit": hierarchy_info.get("final_group_unit", ""),  # –£—Ä–æ–≤–µ–Ω—å 6: –ì—Ä—É–ø–ø–∞
                "hierarchy_level": hierarchy_info.get(
                    "hierarchy_level", 1
                ),  # –ù–æ–º–µ—Ä —É—Ä–æ–≤–Ω—è –≤ –∏–µ—Ä–∞—Ä—Ö–∏–∏
                "full_hierarchy_path": hierarchy_info.get(
                    "full_hierarchy_path", department
                ),  # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
                # –†–ê–ó–õ–û–ñ–ï–ù–ò–ï –ò–ï–†–ê–†–•–ò–ò (–ø–ª–æ—Å–∫–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è Langfuse)
                "hierarchy_levels_list": ", ".join(
                    hierarchy_info.get("full_path_parts", [department])
                ),
                "hierarchy_current_level": hierarchy_info.get("hierarchy_level", 1),
                "hierarchy_final_unit": hierarchy_info.get("final_unit", department),
                "position_location": f"{hierarchy_info.get('final_unit', department)}/{position}",
                # –ú–ï–¢–ê–î–ê–ù–ù–´–ï
                "generation_timestamp": datetime.now().isoformat(),
                "data_version": "v1.3",  # v1.3: Added KPI templates for 100% coverage + metadata tracking
            }

            # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            estimated_tokens = self._estimate_tokens(variables)
            variables["estimated_input_tokens"] = estimated_tokens

            logger.info(f"Variables prepared successfully. Estimated tokens: {estimated_tokens}")
            return variables

        except Exception as e:
            logger.error(f"Error preparing Langfuse variables: {e}")
            raise

    def _detect_kpi_source(self, department: str) -> Dict[str, str]:
        """
        Detect KPI source: specific file or generic template.

        Args:
            department: Department name

        Returns:
            Dict with 'source' and 'dept_type' metadata
        """
        # Check if specific KPI file exists
        kpi_filename = self.kpi_mapper.find_kpi_file(department)

        # Handle None case (no KPI file found - 71.2% of departments)
        if kpi_filename is None:
            # Using template if available
            if self.kpi_mapper.templates_available:
                dept_type = self.kpi_mapper.detect_department_type(department)
                return {"source": "template", "dept_type": dept_type, "kpi_file": None}

            # No KPI and no template
            return {"source": "none", "dept_type": "N/A", "kpi_file": None}

        # KPI filename found, check if file exists
        kpi_path = self.kpi_mapper.kpi_dir / kpi_filename

        if kpi_path.exists():
            return {
                "source": "specific",
                "dept_type": "N/A",  # Specific file, no template type
                "kpi_file": kpi_filename,
            }

        # KPI filename exists but file not found - fallback to template
        if self.kpi_mapper.templates_available:
            dept_type = self.kpi_mapper.detect_department_type(department)
            return {"source": "template", "dept_type": dept_type, "kpi_file": None}

        # Last resort fallback
        return {"source": "fallback", "dept_type": "GENERIC", "kpi_file": None}

    def _load_company_map_cached(self) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ä—Ç—ã –∫–æ–º–ø–∞–Ω–∏–∏ –ê101 —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = "company_map"

        if cache_key not in self._cache:
            try:
                with open(self.paths["company_map"], "r", encoding="utf-8") as f:
                    content = f.read()

                self._cache[cache_key] = content
                logger.info(f"Company map loaded: {len(content)} chars")

            except Exception as e:
                logger.error(f"Error loading company map: {e}")
                self._cache[cache_key] = "# –ö–∞—Ä—Ç–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞\n\n–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö."

        return self._cache[cache_key]

    def _get_organization_structure_with_target(self, target_path: str) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–æ–∑–∏—Ü–∏–µ–π.

        –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ª–æ–≥–∏–∫–∏ –∏–∑ CatalogService –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.
        –ù–∞–ø—Ä—è–º—É—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç organization_cache.

        Args:
            target_path: –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ü–µ–ª–µ–≤–æ–π –±–∏–∑–Ω–µ—Å-–µ–¥–∏–Ω–∏—Ü–µ (department/position)

        Returns:
            Dict[str, Any]: –ü–æ–ª–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–π —Ü–µ–ª—å—é
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ –ø—É—Ç–∏
            target_unit = organization_cache.find_unit_by_path(target_path)
            if not target_unit:
                logger.warning(f"Target path not found: {target_path}")
                return {
                    "error": f"Business unit at path '{target_path}' not found",
                    "available_paths": list(
                        organization_cache.get_all_business_units_with_paths().keys()
                    )[
                        :10
                    ],  # –ü–µ—Ä–≤—ã–µ 10 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
                }

            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –ø–æ–¥—Å–≤–µ—á–µ–Ω–Ω–æ–π —Ü–µ–ª—å—é
            highlighted_structure = organization_cache.get_structure_with_target_highlighted(
                target_path
            )

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è LLM (–∫–æ–ø–∏—è –ª–æ–≥–∏–∫–∏ –∏–∑ CatalogService)
            highlighted_structure["target_unit_info"] = {
                "name": target_unit["name"],
                "full_path": target_path,
                "positions_count": len(target_unit["positions"]),
                "positions": target_unit["positions"],
                "hierarchy_level": target_unit["level"],
            }

            logger.debug(f"‚úÖ Generated structure with target: {target_path}")
            return highlighted_structure

        except Exception as e:
            logger.error(f"‚ùå Error getting organization structure with target: {e}")
            return {
                "error": f"Failed to retrieve organization structure: {str(e)}",
                "target_path": target_path,
            }

    def _load_org_structure_for_department(self, department: str) -> dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–µ—à–∞"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–µ—à –≤–º–µ—Å—Ç–æ –ø—Ä—è–º–æ–≥–æ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞
            dept_info = organization_cache.find_department(department)

            if dept_info:
                dept_node = dept_info["node"]
                return {
                    "department_path": dept_info["path"],
                    "structure": {
                        "name": department,
                        "number": dept_node.get("number"),
                        "positions": dept_node.get("positions", []),
                        "children": dept_node.get("children", {}),
                    },
                    "found": True,
                }
            else:
                logger.warning(f"Department not found in cache: {department}")
                return {
                    "department_path": department,
                    "structure": {"name": department, "positions": []},
                    "found": False,
                }

        except Exception as e:
            logger.error(f"Error loading organization structure from cache: {e}")
            return {
                "department_path": department,
                "structure": {"name": department, "positions": []},
                "found": False,
                "error": str(e),
            }

    def _load_it_systems_cached(self) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ IT —Å–∏—Å—Ç–µ–º –∏–∑ anonymized_digitization_map.md —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = "it_systems"

        if cache_key not in self._cache:
            try:
                with open(self.paths["it_systems"], "r", encoding="utf-8") as f:
                    content = f.read()

                self._cache[cache_key] = content
                logger.info(f"IT systems loaded: {len(content)} chars")

            except Exception as e:
                logger.error(f"Error loading IT systems: {e}")
                self._cache[cache_key] = (
                    "# IT —Å–∏—Å—Ç–µ–º—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã\n\n–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –æ–± IT —Å–∏—Å—Ç–µ–º–∞—Ö."
                )

        return self._cache[cache_key]

    def _load_it_systems_conditional(self, position: str, department: str) -> str:
        """
        Load IT systems with conditional complexity based on position type.

        Args:
            position: Position name
            department: Department name

        Returns:
            IT systems content tailored to position type
        """
        # Detect position type
        pos_type = detect_position_type(position, department)

        # Load full content
        full_content = self._load_it_systems_cached()

        # Apply compression based on type
        if pos_type == PositionType.IT_TECHNICAL:
            # Full content (~15K tokens)
            tokens = len(full_content) / 3.5
            logger.info(f"IT_TECHNICAL: Loading full IT systems (~{tokens:.0f} tokens)")
            return full_content

        elif pos_type == PositionType.IT_MANAGEMENT:
            # Summary + key systems (~3K tokens)
            compressed = self._compress_it_systems_for_management(full_content)
            tokens = len(compressed) / 3.5
            logger.info(f"IT_MANAGEMENT: Loading compressed IT systems (~{tokens:.0f} tokens)")
            return compressed

        elif pos_type == PositionType.BUSINESS_TECHNICAL:
            # Business systems only (~5K tokens)
            business_only = self._extract_business_systems(full_content)
            tokens = len(business_only) / 3.5
            logger.info(f"BUSINESS_TECHNICAL: Loading business systems (~{tokens:.0f} tokens)")
            return business_only

        else:  # BUSINESS_GENERAL or SUPPORT
            # High-level overview (~1K tokens)
            minimal = self._compress_it_systems_minimal(full_content)
            tokens = len(minimal) / 3.5
            logger.info(f"{pos_type.value}: Loading minimal IT systems (~{tokens:.0f} tokens)")
            return minimal

    def _parse_markdown_sections(self, content: str) -> Dict[str, str]:
        """
        Parse markdown content into sections by headers.

        Args:
            content: Markdown content

        Returns:
            Dict mapping header to section content
        """
        sections = {}
        current_header = None
        current_content = []

        for line in content.split("\n"):
            if line.startswith("#"):
                if current_header:
                    sections[current_header] = "\n".join(current_content)
                current_header = line
                current_content = []
            else:
                current_content.append(line)

        if current_header:
            sections[current_header] = "\n".join(current_content)

        return sections

    def _compress_it_systems_for_management(self, full_content: str) -> str:
        """
        Compress IT systems for management roles.

        Include:
        - Overview section
        - Key strategic systems (first 3 items from each category)
        Omit:
        - Detailed system lists beyond first 3 items

        Target: ~3K tokens (10K chars)

        Args:
            full_content: Full IT systems content

        Returns:
            Compressed content for management
        """
        lines = full_content.split("\n")
        compressed = []
        current_category = None
        items_in_category = 0
        max_items_per_category = 3

        for line in lines:
            # Keep headers and warnings
            if line.startswith("#") or line.startswith(">"):
                compressed.append(line)
                if line.startswith("###"):
                    current_category = line
                    items_in_category = 0
            # Keep first N items per category
            elif line.startswith("-") and current_category:
                if items_in_category < max_items_per_category:
                    compressed.append(line)
                    items_in_category += 1
                elif items_in_category == max_items_per_category:
                    compressed.append(
                        f"- *...–∏ –¥—Ä—É–≥–∏–µ —Å–∏—Å—Ç–µ–º—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {current_category.replace('###', '').strip()}*"
                    )
                    items_in_category += 1  # Increment to prevent repeated ellipsis
            elif not line.strip():
                compressed.append(line)

        result = "\n".join(compressed)

        # Ensure target size (~10K chars)
        if len(result) > 10000:
            result = (
                result[:10000] + "\n\n*[...—Å–æ–∫—Ä–∞—â–µ–Ω–æ –¥–ª—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä—É–∫–æ–≤–æ–¥—è—â–µ–π –ø–æ–∑–∏—Ü–∏–∏...]*"
            )

        return result

    def _extract_business_systems(self, full_content: str) -> str:
        """
        Extract only business-facing systems.

        Include categories:
        - –ú–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ –ø—Ä–æ–¥–∞–∂–∏
        - –ü–µ—Ä—Å–æ–Ω–∞–ª –∏ HR
        - –î–æ–∫—É–º–µ–Ω—Ç–æ–æ–±–æ—Ä–æ—Ç –∏ –¥–µ–ª–æ–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ
        - –ë—é–¥–∂–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ñ–∏–Ω–∞–Ω—Å—ã
        - –ü–µ—Ä–µ–¥–∞—á–∞ –∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è

        Omit:
        - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ (infrastructure)
        - Deep technical details

        Target: ~5K tokens (15K chars)

        Args:
            full_content: Full IT systems content

        Returns:
            Business-oriented systems content
        """
        business_categories = [
            "–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ –ø—Ä–æ–¥–∞–∂–∏",
            "–ü–µ—Ä—Å–æ–Ω–∞–ª –∏ HR",
            "–î–æ–∫—É–º–µ–Ω—Ç–æ–æ–±–æ—Ä–æ—Ç –∏ –¥–µ–ª–æ–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ",
            "–ë—é–¥–∂–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ñ–∏–Ω–∞–Ω—Å—ã",
            "–ü–µ—Ä–µ–¥–∞—á–∞ –∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è",
            "–ó–∞–∫—É–ø–∫–∏ –∏ —Å–Ω–∞–±–∂–µ–Ω–∏–µ",
            "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å",
        ]

        lines = full_content.split("\n")
        business_lines = []
        in_business_section = False
        current_section = None

        for line in lines:
            # Check if we're entering a business category
            if line.startswith("###"):
                section_name = (
                    line.replace("###", "").strip().split(".")[1].strip() if "." in line else ""
                )
                if any(cat in section_name for cat in business_categories):
                    in_business_section = True
                    current_section = section_name
                    business_lines.append(line)
                else:
                    in_business_section = False

            elif in_business_section:
                business_lines.append(line)

        if not business_lines:
            # Fallback to minimal if no business sections found
            return self._compress_it_systems_minimal(full_content)

        result = "# IT-—Å–∏—Å—Ç–µ–º—ã (–±–∏–∑–Ω–µ—Å-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)\n\n"
        result += "> –§–æ–∫—É—Å –Ω–∞ —Å–∏—Å—Ç–µ–º–∞—Ö, –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –≤ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–∞—Ö\n\n"
        result += "\n".join(business_lines)

        # Limit to ~15K chars
        if len(result) > 15000:
            result = result[:15000] + "\n\n*[...—Å–æ–∫—Ä–∞—â–µ–Ω–æ –¥–ª—è —Ñ–æ–∫—É—Å–∞ –Ω–∞ –±–∏–∑–Ω–µ—Å-—Å–∏—Å—Ç–µ–º–∞—Ö...]*"

        return result

    def _compress_it_systems_minimal(self, full_content: str) -> str:
        """
        Minimal IT systems overview for non-technical roles.

        Just key systems overview with 3-5 bullet points per category.
        Target: ~1K tokens (3K chars)

        Args:
            full_content: Full IT systems content (unused, for consistency)

        Returns:
            Minimal overview
        """
        return """# IT-—Å–∏—Å—Ç–µ–º—ã –∫–æ–º–ø–∞–Ω–∏–∏ (–æ–±–∑–æ—Ä)

> –û–±—â–∏–π –æ–±–∑–æ—Ä –∫–ª—é—á–µ–≤—ã—Ö –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —Å–∏—Å—Ç–µ–º

## –û—Å–Ω–æ–≤–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–∏—Å—Ç–µ–º

### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏
- **ERP-—Å–∏—Å—Ç–µ–º–∞** ‚Äî –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤, —É—á–µ—Ç, —Ñ–∏–Ω–∞–Ω—Å—ã
- **ECM-—Å–∏—Å—Ç–µ–º–∞** ‚Äî —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º –∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–æ–±–æ—Ä–æ—Ç–æ–º
- **CRM-—Å–∏—Å—Ç–µ–º–∞** ‚Äî —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∂–∞–º–∏ –∏ –≤–∑–∞–∏–º–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è–º–∏ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏

### –ü—Ä–æ–µ–∫—Ç–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å
- **–°–∏—Å—Ç–µ–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞–º–∏** ‚Äî –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∫–æ–Ω—Ç—Ä–æ–ª—å –ø—Ä–æ–µ–∫—Ç–æ–≤
- **CAD/BIM-—Å–∏—Å—Ç–µ–º—ã** ‚Äî –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
- **–°–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞** ‚Äî –Ω–∞–¥–∑–æ—Ä –∑–∞ –æ–±—ä–µ–∫—Ç–∞–º–∏

### –ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –∏ —Å–æ–≤–º–µ—Å—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞
- **–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞** ‚Äî —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞ –∏ –∫–∞–ª–µ–Ω–¥–∞—Ä–∏
- **–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä** ‚Äî –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏
- **–í–ö–°-–ø–ª–∞—Ç—Ñ–æ—Ä–º–∞** ‚Äî –≤–∏–¥–µ–æ–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏ –∏ –æ–Ω–ª–∞–π–Ω-–≤—Å—Ç—Ä–µ—á–∏

### HR –∏ –∫–∞–¥—Ä—ã
- **–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ—Ä—Ç–∞–ª** ‚Äî –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø–æ—Ä—Ç–∞–ª —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
- **–°–∏—Å—Ç–µ–º–∞ –∑–∞—Ä–ø–ª–∞—Ç—ã –∏ –∫–∞–¥—Ä–æ–≤** ‚Äî —Ä–∞—Å—á–µ—Ç –∑–∞—Ä–ø–ª–∞—Ç—ã –∏ –∫–∞–¥—Ä–æ–≤—ã–π —É—á–µ—Ç
- **–°–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è** ‚Äî –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

**–î–ª—è —Ä–∞–±–æ—Ç—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –¥–æ—Å—Ç—É–ø –∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º —Å–∏—Å—Ç–µ–º–∞–º —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–ª–∂–Ω–æ—Å—Ç–Ω—ã–º –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç—è–º.**
"""

    def _load_architect_examples_cached(self) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø—Ä–æ—Ñ–∏–ª–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–æ–≤ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = "architect_examples"

        if cache_key not in self._cache:
            # –ü–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–æ Excel —Ñ–∞–π–ª, –º—ã –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –µ–≥–æ –∫–∞–∫ —Ç–µ–∫—Å—Ç
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç pandas –¥–ª—è —á—Ç–µ–Ω–∏—è Excel
            # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º placeholder
            self._cache[
                cache_key
            ] = """# –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ—Ñ–∏–ª–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–æ–≤

–î–∞–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–æ—Ñ–∏–ª–µ–π —Å–ª—É–∂–∞—Ç —ç—Ç–∞–ª–æ–Ω–æ–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–æ–≤—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π.

[PLACEHOLDER: –ó–¥–µ—Å—å –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–æ–≤ –∏–∑ Excel —Ñ–∞–π–ª–∞]

–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π:
- –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ (3-7 –∑–∞–¥–∞—á –∫–∞–∂–¥–∞—è)
- –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ —Å —á–µ—Ç–∫–∏–º–∏ —É—Ä–æ–≤–Ω—è–º–∏
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –ê101
- –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∫–∞—Ä—å–µ—Ä–Ω—ã–µ –ø—É—Ç–∏
- –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
"""
            logger.warning("Architect examples placeholder loaded (Excel parsing not implemented)")

        return self._cache[cache_key]

    def _load_profile_schema_cached(self) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ JSON —Å—Ö–µ–º—ã –ø—Ä–æ—Ñ–∏–ª—è —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = "profile_schema"

        if cache_key not in self._cache:
            try:
                with open(self.paths["json_schema"], "r", encoding="utf-8") as f:
                    schema_data = json.load(f)

                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∏—Ç–∞–±–µ–ª—å–Ω—É—é JSON —Å—Ç—Ä–æ–∫—É
                self._cache[cache_key] = json.dumps(schema_data, ensure_ascii=False, indent=2)
                logger.info("Profile JSON schema loaded")

            except Exception as e:
                logger.error(f"Error loading profile schema: {e}")
                self._cache[cache_key] = '{"error": "Schema not available"}'

        return self._cache[cache_key]

    def _load_relevant_it_systems(self, department: str) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö IT —Å–∏—Å—Ç–µ–º –¥–ª—è –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞"""
        it_systems_dir = self.paths["it_systems_dir"]

        if not it_systems_dir.exists():
            return "# IT —Å–∏—Å—Ç–µ–º—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã\n\n–î–∞–Ω–Ω—ã–µ –æ–± IT —Å–∏—Å—Ç–µ–º–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."

        # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ IT —Å–∏—Å—Ç–µ–º
        relevant_files = []

        # –ò—â–µ–º —Ñ–∞–π–ª—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
        for file_path in it_systems_dir.glob("*.md"):
            filename = file_path.name.lower()
            dept_lower = department.lower()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—É
            if any(
                keyword in filename
                for keyword in [
                    dept_lower,
                    dept_lower.replace(" ", "_"),
                    dept_lower.replace("–¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç", "dept"),
                    ("–æ–±—â–∏–π" if "—Ñ–∏–Ω–∞–Ω—Å" in dept_lower or "–∫–æ–º–º–µ—Ä—á" in dept_lower else ""),
                ]
            ):
                relevant_files.append(file_path)

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –∏—â–µ–º –æ–±—â–∏–µ
        if not relevant_files:
            for file_path in it_systems_dir.glob("*.md"):
                filename = file_path.name.lower()
                if any(
                    keyword in filename
                    for keyword in ["general", "–æ–±—â–∏–π", "corporate", "–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω"]
                ):
                    relevant_files.append(file_path)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        combined_content = []

        for file_path in relevant_files[:3]:  # –ú–∞–∫—Å–∏–º—É–º 3 —Ñ–∞–π–ª–∞ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è —Ç–æ–∫–µ–Ω–æ–≤
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                combined_content.append(f"## {file_path.stem}\n\n{content}")

            except Exception as e:
                logger.error(f"Error loading IT systems file {file_path}: {e}")

        if not combined_content:
            return f"# IT —Å–∏—Å—Ç–µ–º—ã –¥–ª—è {department}\n\n–°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ IT —Å–∏—Å—Ç–µ–º–∞–º –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã."

        result = "\n\n---\n\n".join(combined_content)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É (–º–∞–∫—Å–∏–º—É–º 20K —Ç–æ–∫–µ–Ω–æ–≤ ‚âà 60K —Å–∏–º–≤–æ–ª–æ–≤)
        if len(result) > 60000:
            result = result[:60000] + "\n\n[...–∫–æ–Ω—Ç–µ–Ω—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤...]"
            logger.warning("IT systems content truncated due to length")

        logger.info(
            f"IT systems loaded for '{department}': {len(relevant_files)} files, {len(result)} chars"
        )
        return result

    def _estimate_tokens(self, variables: Dict[str, Any]) -> int:
        """–ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤"""
        total_chars = 0

        for key, value in variables.items():
            if isinstance(value, str):
                total_chars += len(value)
            elif isinstance(value, (dict, list)):
                total_chars += len(json.dumps(value, ensure_ascii=False))

        # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞: 1 —Ç–æ–∫–µ–Ω ‚âà 3.5 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        estimated_tokens = int(total_chars / 3.5)

        return estimated_tokens

    def load_full_organization_structure(self) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º.

        Returns:
            Dict —Å –ø–æ–ª–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤ –∏ –ø–æ–∑–∏—Ü–∏–π
        """
        cache_key = "full_org_structure"

        if cache_key not in self._cache:
            start_time = datetime.now()
            logger.info("Loading full organization structure...")

            # –î–∞–Ω–Ω—ã–µ —Ç–µ–ø–µ—Ä—å –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–µ—à
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –Ω—É–∂–Ω–∞, —Ç–∞–∫ –∫–∞–∫ –∫–µ—à –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥
            full_structure = {
                "departments": {},
                "metadata": {
                    "total_departments": 0,
                    "total_positions": 0,
                    "loaded_at": start_time.isoformat(),
                },
            }

            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã
            all_departments = (
                list(self.org_mapper._department_index.keys())
                if self.org_mapper._department_index
                else []
            )

            for dept_name in all_departments:
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
                positions = self._get_positions_for_department_internal(dept_name)

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
                dept_path = self.org_mapper.find_department_path(dept_name)

                # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–µ
                dept_info = {
                    "name": dept_name,
                    "path": dept_path,
                    "positions": [
                        {
                            "name": pos_name,
                            "level": self._determine_position_level(pos_name),
                            "category": self._determine_position_category(pos_name),
                        }
                        for pos_name in positions
                    ],
                    "positions_count": len(positions),
                }

                full_structure["departments"][dept_name] = dept_info
                full_structure["metadata"]["total_positions"] += len(positions)

            full_structure["metadata"]["total_departments"] = len(all_departments)

            # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            self._cache[cache_key] = full_structure

            load_time = (datetime.now() - start_time).total_seconds()
            logger.info(
                f"‚úÖ Full organization structure loaded in {load_time:.3f}s: "
                f"{full_structure['metadata']['total_departments']} departments, "
                f"{full_structure['metadata']['total_positions']} positions"
            )

        return self._cache[cache_key]

    def get_available_departments(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥
        full_structure = self.load_full_organization_structure()
        return list(full_structure["departments"].keys())

    def _get_positions_for_department_internal(self, department: str) -> List[str]:
        """–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π –æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —á–µ—Ä–µ–∑ OrganizationMapper
            real_positions = self.org_mapper.get_positions_for_department(department)

            if real_positions:
                logger.debug(
                    f"Found {len(real_positions)} real positions for '{department}' in org structure"
                )
                return real_positions
            else:
                logger.warning(
                    f"No positions found in org structure for '{department}', using fallback"
                )
                # –¢–æ–ª—å–∫–æ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π fallback –∏–∑ –æ–±—â–∏—Ö –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π
                return ["–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç", "–í–µ–¥—É—â–∏–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç", "–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å"]

        except Exception as e:
            logger.error(f"Error getting positions for {department}: {e}")
            return ["–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç"]  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π fallback

    def _determine_position_level(self, position_name: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é"""
        from ..utils.position_utils import determine_position_level

        return determine_position_level(position_name, "string")

    def _determine_position_category(self, position_name: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏"""
        from ..utils.position_utils import determine_position_category

        return determine_position_category(position_name)

    def get_positions_for_department(self, department: str) -> List[str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–æ–ª–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞.
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–æ–ª–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            full_structure = self.load_full_organization_structure()

            if department in full_structure["departments"]:
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–º–µ–Ω–∞ –ø–æ–∑–∏—Ü–∏–π –∏–∑ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                positions = [
                    pos["name"] for pos in full_structure["departments"][department]["positions"]
                ]
                return positions
            else:
                logger.warning(f"Department '{department}' not found in organization structure")
                return []

        except Exception as e:
            logger.error(f"Error getting positions for department '{department}': {e}")
            # Fallback to internal method
            return self._get_positions_for_department_internal(department)

    def _extract_full_position_path(self, department: str, position: str) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø—É—Ç–∏ –¥–æ –ø–æ–∑–∏—Ü–∏–∏ –≤–∫–ª—é—á–∞—è –≤—Å–µ —É—Ä–æ–≤–Ω–∏ –∏–µ—Ä–∞—Ä—Ö–∏–∏.

        Args:
            department: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è)
            position: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏

        Returns:
            Dict —Å –ø–æ–ª–Ω—ã–º –ø—É—Ç–µ–º –∏ —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ–º –ø–æ —É—Ä–æ–≤–Ω—è–º
        """
        try:
            # üî• FIX: –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –ø–æ–ª–Ω—ã–π –ø—É—Ç—å, –∏–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç –∫–∞–∫ –∏–º—è –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
            if "/" in department:
                department_parts = [p.strip() for p in department.split("/") if p.strip()]
                department_name = department_parts[-1]  # –ü–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç = –∏–º—è –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
                logger.info(
                    f"Extracted department name '{department_name}' from full path '{department}'"
                )
            else:
                department_name = department

            # –°–Ω–∞—á–∞–ª–∞ –Ω–∞—Ö–æ–¥–∏–º –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –ø–æ –∫–æ—Ä–æ—Ç–∫–æ–º—É –∏–º–µ–Ω–∏
            dept_info = organization_cache.find_department(department_name)
            if not dept_info:
                logger.warning(f"Department not found: {department_name}")
                return self._create_fallback_hierarchy_info(department_name, position)

            # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—ã–π –ø—É—Ç—å –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
            dept_path = dept_info["path"]
            path_parts = [p.strip() for p in dept_path.split("/") if p.strip()]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–æ–∑–∏—Ü–∏—è –≤ –¥–µ—Ç—è—Ö –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
            dept_node = dept_info["node"]
            positions_in_dept = dept_node.get("positions", [])

            # –ï—Å–ª–∏ –ø–æ–∑–∏—Ü–∏—è –Ω–∞–π–¥–µ–Ω–∞ –ø—Ä—è–º–æ –≤ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–µ
            if position in positions_in_dept:
                full_path_parts = path_parts
                final_unit = department
            else:
                # –ò—â–µ–º –ø–æ–∑–∏—Ü–∏—é –≤ –¥–æ—á–µ—Ä–Ω–∏—Ö –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è—Ö
                position_unit, position_path = self._find_position_in_children(
                    dept_node, position, dept_path
                )
                if position_unit:
                    full_path_parts = [p.strip() for p in position_path.split("/") if p.strip()]
                    final_unit = position_unit
                else:
                    # –ü–æ–∑–∏—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç
                    logger.warning(
                        f"Position '{position}' not found in structure, using department level"
                    )
                    full_path_parts = path_parts
                    final_unit = department

            return self._build_hierarchy_info(full_path_parts, final_unit, position)

        except Exception as e:
            logger.error(f"Error extracting full position path: {e}")
            return self._create_fallback_hierarchy_info(department, position)

    def _find_position_in_children(
        self, node: dict, target_position: str, current_path: str
    ) -> tuple:
        """
        –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ–∑–∏—Ü–∏–∏ –≤ –¥–æ—á–µ—Ä–Ω–∏—Ö –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è—Ö.

        Returns:
            tuple: (unit_name, full_path) –∏–ª–∏ (None, None)
        """
        children = node.get("children", {})
        for child_name, child_data in children.items():
            child_path = f"{current_path}/{child_name}"
            child_positions = child_data.get("positions", [])

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ç–µ–∫—É—â–µ–º –¥–æ—á–µ—Ä–Ω–µ–º –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏
            if target_position in child_positions:
                return child_name, child_path

            # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏—â–µ–º –≤ –¥–µ—Ç—è—Ö
            found_unit, found_path = self._find_position_in_children(
                child_data, target_position, child_path
            )
            if found_unit:
                return found_unit, found_path

        return None, None

    def _build_hierarchy_info(
        self, path_parts: List[str], final_unit: str, position: str
    ) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏–µ—Ä–∞—Ä—Ö–∏–∏ (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–æ 6 —É—Ä–æ–≤–Ω–µ–π)"""
        return {
            "full_path_parts": path_parts,
            "hierarchy_level": len(path_parts),
            "business_block": path_parts[0] if len(path_parts) > 0 else "",
            "department_unit": (
                path_parts[1] if len(path_parts) > 1 else path_parts[0] if path_parts else ""
            ),
            "section_unit": path_parts[2] if len(path_parts) > 2 else "",
            "group_unit": path_parts[3] if len(path_parts) > 3 else "",
            "sub_section_unit": path_parts[4] if len(path_parts) > 4 else "",  # –£—Ä–æ–≤–µ–Ω—å 5
            "final_group_unit": path_parts[5] if len(path_parts) > 5 else "",  # –£—Ä–æ–≤–µ–Ω—å 6
            "final_unit": final_unit,
            "position": position,
            "full_hierarchy_path": " ‚Üí ".join(path_parts),
            "department_path_legacy": "/".join(path_parts),  # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        }

    def _create_fallback_hierarchy_info(self, department: str, position: str) -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ fallback –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–æ 6 —É—Ä–æ–≤–Ω–µ–π).

        –ï—Å–ª–∏ department —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–Ω—ã–π –ø—É—Ç—å, —Ä–∞–∑–±–∏—Ä–∞–µ–º –µ–≥–æ.
        """
        # üî• FIX: –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –ø–æ–ª–Ω—ã–π –ø—É—Ç—å, —Ä–∞–∑–±–∏—Ä–∞–µ–º –µ–≥–æ
        if "/" in department:
            path_parts = [p.strip() for p in department.split("/") if p.strip()]
            return self._build_hierarchy_info(path_parts, path_parts[-1], position)

        # –ò–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ–π fallback
        return {
            "full_path_parts": [department],
            "hierarchy_level": 1,
            "business_block": "",
            "department_unit": department,
            "section_unit": "",
            "group_unit": "",
            "sub_section_unit": "",  # –£—Ä–æ–≤–µ–Ω—å 5
            "final_group_unit": "",  # –£—Ä–æ–≤–µ–Ω—å 6
            "final_unit": department,
            "position": position,
            "full_hierarchy_path": department,
            "department_path_legacy": department,
        }

    def clear_cache(self):
        """–û—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞ (–ø–æ–ª–µ–∑–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)"""
        self._cache.clear()
        logger.info("Cache cleared")

    def validate_data_sources(self) -> Dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
        validation = {
            "company_map": self.paths["company_map"].exists(),
            "json_schema": self.paths["json_schema"].exists(),
            "it_systems": self.paths["it_systems"].exists(),
            "org_structure": self.paths["org_structure"].exists(),
            "kpi_file": Path("data/KPI/KPI_DIT.md").exists(),
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º KPI —Ñ–∞–π–ª—ã
        kpi_validation = self.kpi_mapper.validate_kpi_mappings()
        validation["kpi_files"] = all(kpi_validation.values())

        return validation


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ DataLoader
    logging.basicConfig(level=logging.INFO)

    print("=== –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ DataLoader ===")
    loader = DataLoader()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö
    validation = loader.validate_data_sources()
    print("–í–∞–ª–∏–¥–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö:")
    for source, status in validation.items():
        print(f"  {source}: {'‚úÖ' if status else '‚ùå'}")

    print("\n=== –¢–µ—Å—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö ===")
    try:
        variables = loader.prepare_langfuse_variables(
            department="–î–ò–¢",
            position="–ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä —Ä–µ—à–µ–Ω–∏–π",
            employee_name="–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á",
        )

        print("–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
        print(f"  - –î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç: {variables['department']}")
        print(f"  - –ü—É—Ç—å –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ: {variables['department_path']}")
        print(f"  - –î–æ–ª–∂–Ω–æ—Å—Ç—å: {variables['position']}")
        print(f"  - –û—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤: {variables['estimated_input_tokens']}")
        print(f"  - –†–∞–∑–º–µ—Ä –∫–∞—Ä—Ç—ã –∫–æ–º–ø–∞–Ω–∏–∏: {len(variables['company_map'])} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"  - –†–∞–∑–º–µ—Ä KPI –¥–∞–Ω–Ω—ã—Ö: {len(variables['kpi_data'])} —Å–∏–º–≤–æ–ª–æ–≤")

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")

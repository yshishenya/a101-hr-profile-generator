"""
DataLoader —Å –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ñ–∏–ª–µ–π –ê101.

–û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –º–∞–ø–ø–∏–Ω–≥–∞
–¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ Langfuse –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–∞.
"""

import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List
import logging

from .data_mapper import OrganizationMapper, KPIMapper
from .organization_cache import organization_cache

logger = logging.getLogger(__name__)


class DataLoader:
    """
    –ì–ª–∞–≤–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö —Å –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –º–∞–ø–ø–∏–Ω–≥–∞.
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è Langfuse –ø—Ä–æ–º–ø—Ç–æ–≤.
    """

    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∞–ø–ø–∏–Ω–≥–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.org_mapper = OrganizationMapper("data/structure.json")
        self.kpi_mapper = KPIMapper("data/KPI")

        # –ö–µ—à –¥–ª—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        self._cache = {}

        # –ü—É—Ç–∏ –∫ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–º —Ñ–∞–π–ª–∞–º - –≤—Å–µ –≤ ./data
        self.paths = {
            "company_map": Path("data") / "–ö–∞—Ä—Ç–∞ –ö–æ–º–ø–∞–Ω–∏–∏ –ê101.md",
            "org_structure": Path("data") / "structure.json",
            "it_systems": Path("data") / "anonymized_digitization_map.md",
            "json_schema": Path("templates") / "job_profile_schema.json",
        }

    def prepare_langfuse_variables(
        self, department: str, position: str, employee_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –º–∞–ø–ø–∏–Ω–≥–∞ –¥–ª—è Langfuse.

        Args:
            department: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
            position: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏
            employee_name: –§–ò–û —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –°–ª–æ–≤–∞—Ä—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è Langfuse –ø—Ä–æ–º–ø—Ç–∞
        """
        logger.info(f"Preparing variables for {department} - {position}")

        try:
            # üéØ –î–ï–¢–ï–†–ú–ò–ù–ò–†–û–í–ê–ù–ù–û–ï –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´
            org_structure = self._load_org_structure_for_department(department)
            department_path = org_structure.get("department_path", department)

            # üéØ –î–ï–¢–ï–†–ú–ò–ù–ò–†–û–í–ê–ù–ù–´–ô –í–´–ë–û–† KPI –§–ê–ô–õ–ê
            kpi_content = self.kpi_mapper.load_kpi_content(department)
            
            # üéØ –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –î–ê–ù–ù–´–• –û –ß–ò–°–õ–ï–ù–ù–û–°–¢–ò
            headcount_info = self.org_mapper.get_headcount_info(department)
            subordinates_count = self.org_mapper.calculate_subordinates_count(department, position)

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å–µ—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            variables = {
                # –û–°–ù–û–í–ù–û–ô –ö–û–ù–¢–ï–ö–°–¢ (–∫–µ—à–∏—Ä—É–µ—Ç—Å—è)
                "company_map": self._load_company_map_cached(),  # ~110K —Å–∏–º–≤–æ–ª–æ–≤
                "json_schema": self._load_profile_schema_cached(),  # ~1K —Ç–æ–∫–µ–Ω–æ–≤ (–Ω—É–∂–Ω–∞ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞)
                # –†–ï–õ–ï–í–ê–ù–¢–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω–∞—è)
                "org_structure": json.dumps(
                    org_structure, ensure_ascii=False, indent=2
                ),  # ~5K —Ç–æ–∫–µ–Ω–æ–≤
                "department_path": department_path,
                # –ü–û–õ–ù–ê–Ø –û–†–ì–ê–ù–ò–ó–ê–¶–ò–û–ù–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º —Ü–µ–ª–∏
                "OrgStructure": json.dumps(
                    self._get_organization_structure_with_target(
                        f"{department}/{position}"
                    ),
                    ensure_ascii=False,
                    indent=2,
                ),  # ~229K —Å–∏–º–≤–æ–ª–æ–≤ - –ø–æ–ª–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º
                # –ü–û–ó–ò–¶–ò–û–ù–ù–´–ï –î–ê–ù–ù–´–ï
                "position": position,
                "department": department,
                "employee_name": employee_name or "",
                # –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–ô –ö–û–ù–¢–ï–ö–°–¢ (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–π)
                "kpi_data": kpi_content,  # 0-15K —Ç–æ–∫–µ–Ω–æ–≤
                "it_systems": self._load_it_systems_cached(),  # ~15K —Ç–æ–∫–µ–Ω–æ–≤
                # –î–ê–ù–ù–´–ï –û –ß–ò–°–õ–ï–ù–ù–û–°–¢–ò –ò –ü–û–î–ß–ò–ù–ï–ù–ù–´–• (–ù–û–í–û–ï!)
                "headcount_info": headcount_info,  # –ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
                "subordinates_calculation": subordinates_count,  # –†–∞—Å—á–µ—Ç –ø–æ–¥—á–∏–Ω–µ–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                "department_headcount": headcount_info.get("headcount"),  # –ü—Ä—è–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
                "headcount_source": headcount_info.get("headcount_source"),  # –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö –æ —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏
                # –ú–ï–¢–ê–î–ê–ù–ù–´–ï
                "generation_timestamp": datetime.now().isoformat(),
                "data_version": "v1.1",  # –£–≤–µ–ª–∏—á–µ–Ω–∞ –≤–µ—Ä—Å–∏—è –∏–∑-–∑–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏
            }

            # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            estimated_tokens = self._estimate_tokens(variables)
            variables["estimated_input_tokens"] = estimated_tokens

            logger.info(
                f"Variables prepared successfully. Estimated tokens: {estimated_tokens}"
            )
            return variables

        except Exception as e:
            logger.error(f"Error preparing Langfuse variables: {e}")
            raise

    def _load_company_map_cached(self) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ä—Ç—ã –∫–æ–º–ø–∞–Ω–∏–∏ –ê101 —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = "company_map"

        if cache_key not in self._cache:
            try:
                with open(self.paths["company_map"], "r", encoding="utf-8") as f:
                    content = f.read()

                self._cache[cache_key] = content
                logger.info(f"Company map loaded: {len(content)} chars")

            except Exception as e:
                logger.error(f"Error loading company map: {e}")
                self._cache[cache_key] = (
                    "# –ö–∞—Ä—Ç–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞\n\n–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö."
                )

        return self._cache[cache_key]
    
    def _get_organization_structure_with_target(self, target_path: str) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–æ–∑–∏—Ü–∏–µ–π.
        
        –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ª–æ–≥–∏–∫–∏ –∏–∑ CatalogService –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.
        –ù–∞–ø—Ä—è–º—É—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç organization_cache.
        
        Args:
            target_path: –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ü–µ–ª–µ–≤–æ–π –±–∏–∑–Ω–µ—Å-–µ–¥–∏–Ω–∏—Ü–µ (department/position)
        
        Returns:
            Dict[str, Any]: –ü–æ–ª–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–π —Ü–µ–ª—å—é
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ –ø—É—Ç–∏  
            target_unit = organization_cache.find_unit_by_path(target_path)
            if not target_unit:
                logger.warning(f"Target path not found: {target_path}")
                return {
                    "error": f"Business unit at path '{target_path}' not found",
                    "available_paths": list(
                        organization_cache.get_all_business_units_with_paths().keys()
                    )[:10],  # –ü–µ—Ä–≤—ã–µ 10 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
                }

            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –ø–æ–¥—Å–≤–µ—á–µ–Ω–Ω–æ–π —Ü–µ–ª—å—é
            highlighted_structure = organization_cache.get_structure_with_target_highlighted(
                target_path
            )

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è LLM (–∫–æ–ø–∏—è –ª–æ–≥–∏–∫–∏ –∏–∑ CatalogService)
            highlighted_structure["target_unit_info"] = {
                "name": target_unit["name"],
                "full_path": target_path,
                "positions_count": len(target_unit["positions"]),
                "positions": target_unit["positions"],
                "hierarchy_level": target_unit["level"],
            }

            logger.debug(f"‚úÖ Generated structure with target: {target_path}")
            return highlighted_structure

        except Exception as e:
            logger.error(f"‚ùå Error getting organization structure with target: {e}")
            return {
                "error": f"Failed to retrieve organization structure: {str(e)}",
                "target_path": target_path,
            }

    def _load_org_structure_for_department(self, department: str) -> dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–µ—à–∞"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–µ—à –≤–º–µ—Å—Ç–æ –ø—Ä—è–º–æ–≥–æ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞
            dept_info = organization_cache.find_department(department)

            if dept_info:
                dept_node = dept_info["node"]
                return {
                    "department_path": dept_info["path"],
                    "structure": {
                        "name": department,
                        "number": dept_node.get("number"),
                        "positions": dept_node.get("positions", []),
                        "children": dept_node.get("children", {}),
                    },
                    "found": True,
                }
            else:
                logger.warning(f"Department not found in cache: {department}")
                return {
                    "department_path": department,
                    "structure": {"name": department, "positions": []},
                    "found": False,
                }

        except Exception as e:
            logger.error(f"Error loading organization structure from cache: {e}")
            return {
                "department_path": department,
                "structure": {"name": department, "positions": []},
                "found": False,
                "error": str(e),
            }

    def _load_it_systems_cached(self) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ IT —Å–∏—Å—Ç–µ–º –∏–∑ anonymized_digitization_map.md —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = "it_systems"

        if cache_key not in self._cache:
            try:
                with open(self.paths["it_systems"], "r", encoding="utf-8") as f:
                    content = f.read()

                self._cache[cache_key] = content
                logger.info(f"IT systems loaded: {len(content)} chars")

            except Exception as e:
                logger.error(f"Error loading IT systems: {e}")
                self._cache[cache_key] = (
                    "# IT —Å–∏—Å—Ç–µ–º—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã\n\n–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –æ–± IT —Å–∏—Å—Ç–µ–º–∞—Ö."
                )

        return self._cache[cache_key]

    def _load_architect_examples_cached(self) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø—Ä–æ—Ñ–∏–ª–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–æ–≤ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = "architect_examples"

        if cache_key not in self._cache:
            # –ü–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–æ Excel —Ñ–∞–π–ª, –º—ã –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –µ–≥–æ –∫–∞–∫ —Ç–µ–∫—Å—Ç
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç pandas –¥–ª—è —á—Ç–µ–Ω–∏—è Excel
            # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º placeholder
            self._cache[
                cache_key
            ] = """# –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ—Ñ–∏–ª–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–æ–≤

–î–∞–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–æ—Ñ–∏–ª–µ–π —Å–ª—É–∂–∞—Ç —ç—Ç–∞–ª–æ–Ω–æ–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–æ–≤—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π.

[PLACEHOLDER: –ó–¥–µ—Å—å –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–æ–≤ –∏–∑ Excel —Ñ–∞–π–ª–∞]

–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π:
- –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ (3-7 –∑–∞–¥–∞—á –∫–∞–∂–¥–∞—è)
- –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ —Å —á–µ—Ç–∫–∏–º–∏ —É—Ä–æ–≤–Ω—è–º–∏
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –ê101
- –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∫–∞—Ä—å–µ—Ä–Ω—ã–µ –ø—É—Ç–∏
- –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
"""
            logger.warning(
                "Architect examples placeholder loaded (Excel parsing not implemented)"
            )

        return self._cache[cache_key]

    def _load_profile_schema_cached(self) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ JSON —Å—Ö–µ–º—ã –ø—Ä–æ—Ñ–∏–ª—è —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = "profile_schema"

        if cache_key not in self._cache:
            try:
                with open(self.paths["json_schema"], "r", encoding="utf-8") as f:
                    schema_data = json.load(f)

                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∏—Ç–∞–±–µ–ª—å–Ω—É—é JSON —Å—Ç—Ä–æ–∫—É
                self._cache[cache_key] = json.dumps(
                    schema_data, ensure_ascii=False, indent=2
                )
                logger.info("Profile JSON schema loaded")

            except Exception as e:
                logger.error(f"Error loading profile schema: {e}")
                self._cache[cache_key] = '{"error": "Schema not available"}'

        return self._cache[cache_key]

    def _load_relevant_it_systems(self, department: str) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö IT —Å–∏—Å—Ç–µ–º –¥–ª—è –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞"""
        it_systems_dir = self.paths["it_systems_dir"]

        if not it_systems_dir.exists():
            return "# IT —Å–∏—Å—Ç–µ–º—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã\n\n–î–∞–Ω–Ω—ã–µ –æ–± IT —Å–∏—Å—Ç–µ–º–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."

        # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ IT —Å–∏—Å—Ç–µ–º
        relevant_files = []

        # –ò—â–µ–º —Ñ–∞–π–ª—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
        for file_path in it_systems_dir.glob("*.md"):
            filename = file_path.name.lower()
            dept_lower = department.lower()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—É
            if any(
                keyword in filename
                for keyword in [
                    dept_lower,
                    dept_lower.replace(" ", "_"),
                    dept_lower.replace("–¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç", "dept"),
                    (
                        "–æ–±—â–∏–π"
                        if "—Ñ–∏–Ω–∞–Ω—Å" in dept_lower or "–∫–æ–º–º–µ—Ä—á" in dept_lower
                        else ""
                    ),
                ]
            ):
                relevant_files.append(file_path)

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –∏—â–µ–º –æ–±—â–∏–µ
        if not relevant_files:
            for file_path in it_systems_dir.glob("*.md"):
                filename = file_path.name.lower()
                if any(
                    keyword in filename
                    for keyword in ["general", "–æ–±—â–∏–π", "corporate", "–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω"]
                ):
                    relevant_files.append(file_path)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        combined_content = []

        for file_path in relevant_files[:3]:  # –ú–∞–∫—Å–∏–º—É–º 3 —Ñ–∞–π–ª–∞ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è —Ç–æ–∫–µ–Ω–æ–≤
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                combined_content.append(f"## {file_path.stem}\n\n{content}")

            except Exception as e:
                logger.error(f"Error loading IT systems file {file_path}: {e}")

        if not combined_content:
            return f"# IT —Å–∏—Å—Ç–µ–º—ã –¥–ª—è {department}\n\n–°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ IT —Å–∏—Å—Ç–µ–º–∞–º –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã."

        result = "\n\n---\n\n".join(combined_content)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É (–º–∞–∫—Å–∏–º—É–º 20K —Ç–æ–∫–µ–Ω–æ–≤ ‚âà 60K —Å–∏–º–≤–æ–ª–æ–≤)
        if len(result) > 60000:
            result = (
                result[:60000] + "\n\n[...–∫–æ–Ω—Ç–µ–Ω—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤...]"
            )
            logger.warning("IT systems content truncated due to length")

        logger.info(
            f"IT systems loaded for '{department}': {len(relevant_files)} files, {len(result)} chars"
        )
        return result

    def _estimate_tokens(self, variables: Dict[str, Any]) -> int:
        """–ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤"""
        total_chars = 0

        for key, value in variables.items():
            if isinstance(value, str):
                total_chars += len(value)
            elif isinstance(value, (dict, list)):
                total_chars += len(json.dumps(value, ensure_ascii=False))

        # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞: 1 —Ç–æ–∫–µ–Ω ‚âà 3.5 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        estimated_tokens = int(total_chars / 3.5)

        return estimated_tokens

    def load_full_organization_structure(self) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º.

        Returns:
            Dict —Å –ø–æ–ª–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤ –∏ –ø–æ–∑–∏—Ü–∏–π
        """
        cache_key = "full_org_structure"

        if cache_key not in self._cache:
            start_time = datetime.now()
            logger.info("Loading full organization structure...")

            # –î–∞–Ω–Ω—ã–µ —Ç–µ–ø–µ—Ä—å –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–µ—à
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –Ω—É–∂–Ω–∞, —Ç–∞–∫ –∫–∞–∫ –∫–µ—à –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥
            full_structure = {
                "departments": {},
                "metadata": {
                    "total_departments": 0,
                    "total_positions": 0,
                    "loaded_at": start_time.isoformat(),
                },
            }

            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—ã
            all_departments = (
                list(self.org_mapper._department_index.keys())
                if self.org_mapper._department_index
                else []
            )

            for dept_name in all_departments:
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
                positions = self._get_positions_for_department_internal(dept_name)

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞
                dept_path = self.org_mapper.find_department_path(dept_name)

                # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–µ
                dept_info = {
                    "name": dept_name,
                    "path": dept_path,
                    "positions": [
                        {
                            "name": pos_name,
                            "level": self._determine_position_level(pos_name),
                            "category": self._determine_position_category(pos_name),
                        }
                        for pos_name in positions
                    ],
                    "positions_count": len(positions),
                }

                full_structure["departments"][dept_name] = dept_info
                full_structure["metadata"]["total_positions"] += len(positions)

            full_structure["metadata"]["total_departments"] = len(all_departments)

            # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            self._cache[cache_key] = full_structure

            load_time = (datetime.now() - start_time).total_seconds()
            logger.info(
                f"‚úÖ Full organization structure loaded in {load_time:.3f}s: "
                f"{full_structure['metadata']['total_departments']} departments, "
                f"{full_structure['metadata']['total_positions']} positions"
            )

        return self._cache[cache_key]

    def get_available_departments(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥
        full_structure = self.load_full_organization_structure()
        return list(full_structure["departments"].keys())

    def _get_positions_for_department_internal(self, department: str) -> List[str]:
        """–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π –æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —á–µ—Ä–µ–∑ OrganizationMapper
            real_positions = self.org_mapper.get_positions_for_department(department)

            if real_positions:
                logger.debug(
                    f"Found {len(real_positions)} real positions for '{department}' in org structure"
                )
                return real_positions
            else:
                logger.warning(
                    f"No positions found in org structure for '{department}', using fallback"
                )
                # –¢–æ–ª—å–∫–æ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π fallback –∏–∑ –æ–±—â–∏—Ö –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π
                return ["–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç", "–í–µ–¥—É—â–∏–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç", "–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å"]

        except Exception as e:
            logger.error(f"Error getting positions for {department}: {e}")
            return ["–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç"]  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π fallback

    def _determine_position_level(self, position_name: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é"""
        from ..utils.position_utils import determine_position_level

        return determine_position_level(position_name, "string")

    def _determine_position_category(self, position_name: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏"""
        from ..utils.position_utils import determine_position_category

        return determine_position_category(position_name)

    def get_positions_for_department(self, department: str) -> List[str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–æ–ª–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞.
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–æ–ª–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            full_structure = self.load_full_organization_structure()

            if department in full_structure["departments"]:
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–º–µ–Ω–∞ –ø–æ–∑–∏—Ü–∏–π –∏–∑ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                positions = [
                    pos["name"]
                    for pos in full_structure["departments"][department]["positions"]
                ]
                return positions
            else:
                logger.warning(
                    f"Department '{department}' not found in organization structure"
                )
                return []

        except Exception as e:
            logger.error(f"Error getting positions for department '{department}': {e}")
            # Fallback to internal method
            return self._get_positions_for_department_internal(department)

    def clear_cache(self):
        """–û—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞ (–ø–æ–ª–µ–∑–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)"""
        self._cache.clear()
        logger.info("Cache cleared")

    def validate_data_sources(self) -> Dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
        validation = {
            "company_map": self.paths["company_map"].exists(),
            "json_schema": self.paths["json_schema"].exists(),
            "it_systems": self.paths["it_systems"].exists(),
            "org_structure": self.paths["org_structure"].exists(),
            "kpi_file": Path("data/KPI/KPI_DIT.md").exists(),
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º KPI —Ñ–∞–π–ª—ã
        kpi_validation = self.kpi_mapper.validate_kpi_mappings()
        validation["kpi_files"] = all(kpi_validation.values())

        return validation


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ DataLoader
    logging.basicConfig(level=logging.INFO)

    print("=== –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ DataLoader ===")
    loader = DataLoader()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö
    validation = loader.validate_data_sources()
    print("–í–∞–ª–∏–¥–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö:")
    for source, status in validation.items():
        print(f"  {source}: {'‚úÖ' if status else '‚ùå'}")

    print("\n=== –¢–µ—Å—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö ===")
    try:
        variables = loader.prepare_langfuse_variables(
            department="–î–ò–¢",
            position="–ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä —Ä–µ—à–µ–Ω–∏–π",
            employee_name="–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á",
        )

        print(f"–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
        print(f"  - –î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç: {variables['department']}")
        print(f"  - –ü—É—Ç—å –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ: {variables['department_path']}")
        print(f"  - –î–æ–ª–∂–Ω–æ—Å—Ç—å: {variables['position']}")
        print(f"  - –û—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤: {variables['estimated_input_tokens']}")
        print(f"  - –†–∞–∑–º–µ—Ä –∫–∞—Ä—Ç—ã –∫–æ–º–ø–∞–Ω–∏–∏: {len(variables['company_map'])} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"  - –†–∞–∑–º–µ—Ä KPI –¥–∞–Ω–Ω—ã—Ö: {len(variables['kpi_data'])} —Å–∏–º–≤–æ–ª–æ–≤")

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
